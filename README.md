# A Transformer Model for Posture Recognition

### 模型结构
1.主干网络
  + 使用ResNet-50从输入图像中提取特征图，特征图记为F
2.Transformer编码器
  + 输入到Transformer：将特征图F展开，并通过线性层投射到高维空间中，添加位置嵌入来保留空间信息
  + 层数：使用L层编码器，每层包含多头自注意力机制和前馈神经网络，使用层归一化和残差连接
  + 多头注意力机制：利用H个注意力头来捕捉输入中不同部分的全局依赖关系
  + 前馈网络：两层MLP，使用GeLU激活函数，将维度从D扩展到4D，然后再缩回到D
3.关键点检测Transformer
  + 查询嵌入：引入一组可学习的查询嵌入，每一个关键点一个查询
  + Transformer解码器：使用N层解码器，每层包含注意力（查询对查询）和交叉注意力（查询对特征）。解码器基于编码器的特征逐步优先查询嵌入
  + 位置嵌入：添加层级嵌入（表示特征层级）和像素位置嵌入
4.分类头和回归头
  + 人物检测：一个分类头，用于预测每个对象是否为人；一个回归头，用于预测边界框
  + 关键点回归：对于每个检测到的人，使用一个回归头来预测每个关键点的坐标
5.辅助损失和训练
  + 辅助损失：添加辅助损失以加速收敛
  + 损失函数：结合分类损失、边界狂回归损失和关键点回归损失。使用双边匹配算法来预测的关键点和真实性

### 详细配置
1.CNN主干（ResNet-50）
  + 输入：224*224的RGB图像
  + 输出：大小为7*7*2048的特征
2.Transformer编码器：
  + 输入：带有位置嵌入的展开特征图F
  + 层数：L = 6
  + 注意力头： H = 8
  + 维度：D = 256
3.Transformer解码器
  + 查询嵌入：K = 17 （17个关键点）
  + 层数：N = 6
  + 自注意力头：H = 8
4.头部
  + 人物检测头：用于分类的2层MLP和用于边界框回归的4层MLP
  + 关键点回归头：用于关键点坐标的3层MLP

### 提高性能的技术
1.查询查询对查询注意力：通过捕捉关键点之间的依赖关系来提高模型性能
2.辅助损失：加速收敛并提高整体准确性
3.可变形注意力：增强处理姿态变形的能力
